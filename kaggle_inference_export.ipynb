{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kaggle Inference Export Notebook — Brain-to-Text RNN\n",
        "\n",
        "Instructions:\n",
        "- In Kaggle, create a new Notebook with GPU enabled.\n",
        "- Add these Datasets:\n",
        "  - Dryad data bundle (e.g., `brain-to-text-dryad-bundle`)\n",
        "  - This repository code (e.g., `nejm-brain-to-text`)\n",
        "  - The Output from the Training notebook (contains `trained_models`)\n",
        "- Internet: Off\n",
        "\n",
        "This notebook loads the best checkpoint and exports phoneme logits for val/test for off‑Kaggle LM decoding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Prepare repo and data from attached Datasets\n",
        "cp -r /kaggle/input/nejm-brain-to-text /kaggle/working/nejm-brain-to-text\n",
        "\n",
        "mkdir -p /kaggle/working/nejm-brain-to-text/data\n",
        "cp -r /kaggle/input/brain-to-text-dryad-bundle/hdf5_data_final /kaggle/working/nejm-brain-to-text/data/\n",
        "cp /kaggle/input/brain-to-text-dryad-bundle/t15_copyTaskData_description.csv /kaggle/working/nejm-brain-to-text/data/\n",
        "\n",
        "# Copy trained models from Training notebook output dataset\n",
        "# Replace the dataset name placeholder below with your actual output dataset slug\n",
        "cp -r /kaggle/input/<REPLACE_WITH_TRAINING_OUTPUT_DATASET>/trained_models /kaggle/working/nejm-brain-to-text/model_training/\n",
        "\n",
        "ls -la /kaggle/working/nejm-brain-to-text/model_training/trained_models/baseline_rnn/checkpoint | head -n 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Minimal dependencies for export\n",
        "pip install -q --no-cache-dir \\\n",
        "  numpy==2.0.2 pandas==2.2.2 \\\n",
        "  omegaconf==2.3.0 tqdm==4.66.4 h5py==3.10.0\n",
        "\n",
        "pip install -q -e /kaggle/working/nejm-brain-to-text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export logits for val and test\n",
        "import os, numpy as np, torch\n",
        "from omegaconf import OmegaConf\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from model_training.evaluate_model_helpers import load_h5py_file\n",
        "from model_training.rnn_model import GRUDecoder\n",
        "\n",
        "repo = \"/kaggle/working/nejm-brain-to-text\"\n",
        "data_dir = f\"{repo}/data/hdf5_data_final\"\n",
        "csv_path = f\"{repo}/data/t15_copyTaskData_description.csv\"\n",
        "model_dir = f\"{repo}/model_training/trained_models/baseline_rnn\"\n",
        "args_yaml = f\"{model_dir}/checkpoint/args.yaml\"\n",
        "out_dir = f\"{repo}/model_training/logits_export\"\n",
        "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "args = OmegaConf.load(args_yaml)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = GRUDecoder(\n",
        "    neural_dim = args['model']['n_input_features'],\n",
        "    n_units = args['model']['n_units'],\n",
        "    n_days = len(args['dataset']['sessions']),\n",
        "    n_classes = args['dataset']['n_classes'],\n",
        "    rnn_dropout = args['model']['rnn_dropout'],\n",
        "    input_dropout = args['model']['input_network']['input_layer_dropout'],\n",
        "    n_layers = args['model']['n_layers'],\n",
        "    patch_size = args['model']['patch_size'],\n",
        "    patch_stride = args['model']['patch_stride'],\n",
        ").to(device)\n",
        "\n",
        "ckpt = torch.load(f\"{model_dir}/checkpoint/best_checkpoint\", map_location=device, weights_only=False)\n",
        "for key in list(ckpt['model_state_dict'].keys()):\n",
        "    ckpt['model_state_dict'][key.replace(\"module.\", \"\")] = ckpt['model_state_dict'].pop(key)\n",
        "    ckpt['model_state_dict'][key.replace(\"_orig_mod.\", \"\")] = ckpt['model_state_dict'].pop(key)\n",
        "model.load_state_dict(ckpt['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "b2txt_csv_df = pd.read_csv(csv_path)\n",
        "\n",
        "@torch.no_grad()\n",
        "def export_split(eval_type):\n",
        "    export = {}\n",
        "    total = 0\n",
        "    for session in args['dataset']['sessions']:\n",
        "        files = os.listdir(os.path.join(data_dir, session))\n",
        "        if f\"data_{eval_type}.hdf5\" not in files:\n",
        "            continue\n",
        "        data = load_h5py_file(os.path.join(data_dir, session, f\"data_{eval_type}.hdf5\"), b2txt_csv_df)\n",
        "        export[session] = data\n",
        "        total += len(data[\"neural_features\"])\n",
        "\n",
        "    with tqdm(total=total, desc=f\"Export {eval_type} logits\", unit=\"trial\") as pbar:\n",
        "        for session, data in export.items():\n",
        "            sess_logits = []\n",
        "            day_idx = torch.tensor([args['dataset']['sessions'].index(session)], device=device)\n",
        "            for trial in range(len(data['neural_features'])):\n",
        "                x = data['neural_features'][trial]\n",
        "                x = np.expand_dims(x, axis=0)\n",
        "                x = torch.tensor(x, device=device, dtype=torch.bfloat16)\n",
        "                logits = model(x, day_idx)[0].float().cpu().numpy()  # T x C\n",
        "                sess_logits.append(logits)\n",
        "                pbar.update(1)\n",
        "            np.save(os.path.join(out_dir, f\"{session}_{eval_type}_logits.npy\"), np.array(sess_logits, dtype=np.float32))\n",
        "\n",
        "export_split(\"val\")\n",
        "export_split(\"test\")\n",
        "print(\"Saved to:\", out_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export logits to Notebook Output for download\n",
        "mkdir -p /kaggle/working/export\n",
        "cp -r /kaggle/working/nejm-brain-to-text/model_training/logits_export /kaggle/working/export/\n",
        "ls -R /kaggle/working/export | head -n 60\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
