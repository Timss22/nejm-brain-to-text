{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Brain-to-Text '25 Competition — Colab-First Training Plan (with Kaggle fallback)\n",
        "\n",
        "Goal\n",
        "- Produce a valid competition submission (CSV with id,text) using this repo’s baseline pipeline: GRU phoneme decoder + n‑gram LM (+ optional OPT rescoring).\n",
        "\n",
        "Key facts from the repo\n",
        "- Training code lives in `model_training/` and is driven by `rnn_args.yaml` and `train_model.py`.\n",
        "- Evaluation uses `model_training/evaluate_model.py` and requires a Redis‑connected LM (`language_model/language-model-standalone.py`).\n",
        "- Data path expected: `data/hdf5_data_final/<session>/data_{train|val|test}.hdf5`.\n",
        "\n",
        "Deliverables\n",
        "- Validation WER (for your report) and a test CSV for Kaggle submission.\n",
        "\n",
        "Sequence (high‑level)\n",
        "1) Colab setup and dependency install\n",
        "2) Download data to Drive and verify layout\n",
        "3) Train baseline GRU in Colab\n",
        "4) Start Redis + 1‑gram LM; evaluate on val (compute WER) and test (create CSV)\n",
        "5) If Colab limits block training, train on Kaggle and decode in Colab\n",
        "\n",
        "---\n",
        "\n",
        "## 1) Colab setup (copy/paste cells)\n",
        "\n",
        "1A. Mount Drive and set working directory\n",
        "```bash\n",
        "# Verify GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Use a stable workspace folder in Drive\n",
        "%cd /content/drive/MyDrive\n",
        "!mkdir -p b2txt25\n",
        "%cd b2txt25\n",
        "```\n",
        "\n",
        "1B. Place/point the repo\n",
        "- If you already have the repo in Drive, set its path and skip cloning.\n",
        "```bash\n",
        "# Option A: Reuse existing repo (recommended if already in Drive)\n",
        "%cd /content/drive/MyDrive/nejm-brain-to-text || echo \"Repo not at this path, see Option B\"\n",
        "\n",
        "# Option B: Keep workspace clean, symlink or copy your repo under b2txt25\n",
        "%cd /content/drive/MyDrive/b2txt25\n",
        "!ln -s \"/content/drive/MyDrive/nejm-brain-to-text\" ./nejm-brain-to-text\n",
        "%cd nejm-brain-to-text\n",
        "```\n",
        "\n",
        "1C. Install system + Python deps (conflict‑free set for Colab)\n",
        "```bash\n",
        "# System deps\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y redis-server cmake build-essential\n",
        "\n",
        "# Core GPU stack (CUDA 12.1 wheels on Colab)\n",
        "!pip -q install --upgrade --no-cache-dir \\\n",
        "  torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Remove conflicting HuggingFace libs to avoid resolver issues\n",
        "!pip -q uninstall -y transformers tokenizers huggingface-hub || true\n",
        "\n",
        "# Align with Colab constraints\n",
        "!pip -q install --upgrade --no-cache-dir \\\n",
        "  pandas==2.2.2 \\\n",
        "  numpy==2.0.2\n",
        "\n",
        "# Known-compatible HF trio\n",
        "!pip -q install --no-cache-dir \\\n",
        "  huggingface-hub==0.34.1 \\\n",
        "  transformers==4.53.0 \\\n",
        "  tokenizers==0.21.2\n",
        "\n",
        "# Remaining deps (satisfy umap-learn/tsfresh requirements too)\n",
        "!pip -q install --upgrade --no-cache-dir \\\n",
        "  redis==5.2.1 \\\n",
        "  matplotlib==3.10.1 \\\n",
        "  scipy==1.14.1 \\\n",
        "  scikit-learn==1.6.1 \\\n",
        "  tqdm==4.67.1 \\\n",
        "  g2p_en==2.1.0 \\\n",
        "  h5py==3.11.0 \\\n",
        "  omegaconf==2.3.0 \\\n",
        "  editdistance==0.8.1 \\\n",
        "  accelerate==1.0.1 \\\n",
        "  bitsandbytes==0.43.1\n",
        "\n",
        "# Install local utils package from the repo root\n",
        "%cd /content/drive/MyDrive/nejm-brain-to-text\n",
        "!pip -q install -e .\n",
        "```\n",
        "\n",
        "Troubleshooting (installs)\n",
        "- If you see: “ERROR: file:///content does not appear to be a Python project”, you ran `pip install -e .` outside the repo. `cd` into `…/nejm-brain-to-text` and rerun.\n",
        "- If HF trio conflicts, fallback: `transformers==4.51.0`, `tokenizers==0.20.1`, `huggingface-hub==0.34.1`.\n",
        "\n",
        "---\n",
        "\n",
        "## 2) Data download and verification\n",
        "```bash\n",
        "%cd /content/drive/MyDrive/nejm-brain-to-text\n",
        "!python download_data.py\n",
        "\n",
        "# Quick check (first 80 lines)\n",
        "!ls -R data | head -n 80\n",
        "```\n",
        "\n",
        "Expected structure\n",
        "```\n",
        "data/\n",
        "├── t15_copyTask.pkl\n",
        "├── t15_personalUse.pkl\n",
        "├── hdf5_data_final/\n",
        "│   ├── t15.2023.08.11/\n",
        "│   │   └── data_train.hdf5\n",
        "│   ├── t15.2023.08.13/\n",
        "│   │   ├── data_train.hdf5\n",
        "│   │   ├── data_val.hdf5\n",
        "│   │   └── data_test.hdf5\n",
        "│   └── ... (many sessions)\n",
        "└── t15_pretrained_rnn_baseline/\n",
        "    └── checkpoint/best_checkpoint, args.yaml\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3) Train the baseline GRU (Colab)\n",
        "```bash\n",
        "%cd /content/drive/MyDrive/nejm-brain-to-text/model_training\n",
        "\n",
        "# Optional: quick pipeline check (reduce batches), then restore to 120000 for full run\n",
        "from omegaconf import OmegaConf\n",
        "args = OmegaConf.load('rnn_args.yaml')\n",
        "args.num_training_batches = 120000   # e.g., set 10000 to sanity‑check end‑to‑end\n",
        "args.gpu_number = '0'\n",
        "args.output_dir = 'trained_models/baseline_rnn'\n",
        "args.checkpoint_dir = 'trained_models/baseline_rnn/checkpoint'\n",
        "OmegaConf.save(config=args, f='rnn_args.yaml')\n",
        "\n",
        "# Start training\n",
        "!python train_model.py\n",
        "```\n",
        "\n",
        "Outputs (watch for)\n",
        "- `trained_models/baseline_rnn/training_log`\n",
        "- `trained_models/baseline_rnn/checkpoint/best_checkpoint`\n",
        "- `trained_models/baseline_rnn/checkpoint/val_metrics.pkl`\n",
        "\n",
        "Time\n",
        "- Full 120k batches: fast GPUs ~3.5h; T4 may be longer. Use smaller `num_training_batches` if session time is tight; resume later by pointing to your last checkpoint (set `init_from_checkpoint: true` and `init_checkpoint_path`).\n",
        "\n",
        "---\n",
        "\n",
        "## 4) Language model + evaluation (Colab)\n",
        "\n",
        "4A. Start Redis\n",
        "```bash\n",
        "!redis-server --daemonize yes\n",
        "!redis-cli ping  # expect PONG\n",
        "```\n",
        "\n",
        "4B. Start the 1‑gram LM (keep this cell running)\n",
        "```bash\n",
        "%cd /content/drive/MyDrive/nejm-brain-to-text\n",
        "!python language_model/language-model-standalone.py \\\n",
        "  --lm_path language_model/pretrained_language_models/openwebtext_1gram_lm_sil \\\n",
        "  --do_opt --nbest 100 --acoustic_scale 0.325 --blank_penalty 90 --alpha 0.55 \\\n",
        "  --redis_ip localhost --gpu_number 0\n",
        "```\n",
        "\n",
        "Notes\n",
        "- First run downloads OPT‑6.7b (~13GB). If VRAM is tight on T4, you can remove `--do_opt` (disables OPT rescoring; accuracy drops but RAM usage improves).\n",
        "\n",
        "4C. Evaluate on validation (compute WER)\n",
        "```bash\n",
        "%cd /content/drive/MyDrive/nejm-brain-to-text/model_training\n",
        "!python evaluate_model.py \\\n",
        "  --model_path trained_models/baseline_rnn \\\n",
        "  --data_dir ../data/hdf5_data_final \\\n",
        "  --eval_type val \\\n",
        "  --gpu_number 0\n",
        "```\n",
        "\n",
        "4D. Evaluate on test (produce submission CSV)\n",
        "```bash\n",
        "!python evaluate_model.py \\\n",
        "  --model_path trained_models/baseline_rnn \\\n",
        "  --data_dir ../data/hdf5_data_final \\\n",
        "  --eval_type test \\\n",
        "  --gpu_number 0\n",
        "\n",
        "# Output file lives under the model_path directory:\n",
        "# trained_models/baseline_rnn/baseline_rnn_test_predicted_sentences_YYYYMMDD_HHMMSS.csv\n",
        "```\n",
        "\n",
        "4E. Shutdown Redis (after you finish)\n",
        "```bash\n",
        "!redis-cli shutdown\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5) Kaggle fallback (if Colab training is too slow/unstable)\n",
        "\n",
        "Strategy\n",
        "- Train RNN on Kaggle (GPU notebook). Kaggle may not allow Redis; skip LM there.\n",
        "- Download the trained checkpoint to Drive.\n",
        "- Run LM + `evaluate_model.py` in Colab to create submission CSV.\n",
        "\n",
        "Kaggle steps (high‑level)\n",
        "1) Create a GPU notebook; attach the repo as a Kaggle Dataset (or upload zip).\n",
        "2) `pip install` the same Python deps (skip Redis/LM).\n",
        "3) Run `model_training/train_model.py`; save `trained_models/baseline_rnn/checkpoint/best_checkpoint` to the notebook output.\n",
        "4) Download the model directory; put it in Drive under `…/model_training/trained_models/baseline_rnn`.\n",
        "5) Back in Colab, run Section 4 (LM + evaluation) to generate CSV.\n",
        "\n",
        "---\n",
        "\n",
        "## Troubleshooting quick reference\n",
        "\n",
        "- Dependency conflicts (transformers/tokenizers/hf‑hub)\n",
        "  - Uninstall first, then install compatible trio: `transformers==4.53.0`, `tokenizers==0.21.2`, `huggingface-hub==0.34.1`.\n",
        "- Colab package constraints\n",
        "  - Use `pandas==2.2.2`, `numpy==2.0.2`, `scipy==1.14.1`, `scikit-learn==1.6.1`.\n",
        "- `pip install -e .` error\n",
        "  - Ensure you `cd` to `/content/drive/MyDrive/nejm-brain-to-text` before installing.\n",
        "- LM OOM on T4\n",
        "  - Remove `--do_opt` to skip OPT; or use Colab Pro (A100) for more VRAM.\n",
        "- Session limits\n",
        "  - Lower `num_training_batches` to checkpoint quickly; resume later.\n",
        "\n",
        "---\n",
        "\n",
        "## Timeline (1 month)\n",
        "\n",
        "- Week 1: Environment + data + short training (10k batches) to validate end‑to‑end; produce a test CSV.\n",
        "- Week 2: Full training (120k) on Colab or Kaggle; checkpoint and verify val WER.\n",
        "- Week 3: Iterate hyperparameters if time allows; re‑evaluate; generate improved CSV.\n",
        "- Week 4: Final run, prepare report (include val WER, method, settings) and submit to Kaggle.\n",
        "\n",
        "---\n",
        "\n",
        "Owner checklist\n",
        "- Data present under `data/hdf5_data_final/*`\n",
        "- `trained_models/baseline_rnn/checkpoint/best_checkpoint` exists after training\n",
        "- LM process connected to Redis (shows “Successfully connected…”)\n",
        "- Validation WER printed\n",
        "- Submission CSV generated under model directory\n",
        "\n",
        "Document version: 2.0\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
